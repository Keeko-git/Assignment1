{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTxv5Lj4Hz3V",
        "outputId": "1440e8ca-5ba4-48d4-88c5-6bf3274d6755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/Colab\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "cwwd3yM-J3xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('titanic.csv')\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS9whUTVJ62z",
        "outputId": "2be82b60-61e2-46b8-832f-56e7cae170b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass  \\\n",
            "0              1         0       3   \n",
            "1              2         1       1   \n",
            "2              3         1       3   \n",
            "3              4         1       1   \n",
            "4              5         0       3   \n",
            "..           ...       ...     ...   \n",
            "886          887         0       2   \n",
            "887          888         1       1   \n",
            "888          889         0       3   \n",
            "889          890         1       1   \n",
            "890          891         0       3   \n",
            "\n",
            "                                                  Name     Sex   Age  SibSp  \\\n",
            "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                             Allen, Mr. William Henry    male  35.0      0   \n",
            "..                                                 ...     ...   ...    ...   \n",
            "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
            "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
            "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
            "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
            "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
            "\n",
            "     Parch            Ticket     Fare Cabin Embarked  \n",
            "0        0         A/5 21171   7.2500   NaN        S  \n",
            "1        0          PC 17599  71.2833   C85        C  \n",
            "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3        0            113803  53.1000  C123        S  \n",
            "4        0            373450   8.0500   NaN        S  \n",
            "..     ...               ...      ...   ...      ...  \n",
            "886      0            211536  13.0000   NaN        S  \n",
            "887      0            112053  30.0000   B42        S  \n",
            "888      2        W./C. 6607  23.4500   NaN        S  \n",
            "889      0            111369  30.0000  C148        C  \n",
            "890      0            370376   7.7500   NaN        Q  \n",
            "\n",
            "[891 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z72MYjLeK9uS",
        "outputId": "0c9b9499-aab5-4392-eb58-b50e0294557b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = df[['Survived', 'Pclass', 'SibSp', 'Parch', 'Fare']]\n",
        "titanic_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MYoRhypuLA4b",
        "outputId": "6cdc9558-226a-4f04-a087-e66961bb0d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass  SibSp  Parch     Fare\n",
              "0         0       3      1      0   7.2500\n",
              "1         1       1      1      0  71.2833\n",
              "2         1       3      0      0   7.9250\n",
              "3         1       1      1      0  53.1000\n",
              "4         0       3      0      0   8.0500"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ce66856-31b3-497b-91ac-7ee0ca26f11c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce66856-31b3-497b-91ac-7ee0ca26f11c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ce66856-31b3-497b-91ac-7ee0ca26f11c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ce66856-31b3-497b-91ac-7ee0ca26f11c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(titanic_df[['Pclass', 'SibSp', 'Parch', 'Fare']])\n",
        "X[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe3N7Kv0LIMe",
        "outputId": "b41a449c-3b73-4622-a306-857358f69921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.    ,  1.    ,  0.    ,  7.25  ],\n",
              "       [ 1.    ,  1.    ,  0.    , 71.2833],\n",
              "       [ 3.    ,  0.    ,  0.    ,  7.925 ],\n",
              "       [ 1.    ,  1.    ,  0.    , 53.1   ],\n",
              "       [ 3.    ,  0.    ,  0.    ,  8.05  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(titanic_df['Survived'])\n",
        "y [0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znlFDB5mLOhe",
        "outputId": "e1d9bf0b-3add-4203-ba46-5dee24287fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=stats.zscore(X)\n",
        "X[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZKx3FjwLmg4",
        "outputId": "7280e824-960f-4dbb-ddc7-63c49db189b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.82737724,  0.43279337, -0.47367361, -0.50244517],\n",
              "       [-1.56610693,  0.43279337, -0.47367361,  0.78684529],\n",
              "       [ 0.82737724, -0.4745452 , -0.47367361, -0.48885426],\n",
              "       [-1.56610693,  0.43279337, -0.47367361,  0.42073024],\n",
              "       [ 0.82737724, -0.4745452 , -0.47367361, -0.48633742]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=30)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC9jEBovLuuT",
        "outputId": "d63a3786-ed65-4024-822b-23db17fd8d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (712, 4) (712,)\n",
            "Test set: (179, 4) (179,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "ZL1qByZnL5PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
      ],
      "metadata": {
        "id": "LpwBeoQUMAYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6,activation=\"relu\"))"
      ],
      "metadata": {
        "id": "RJFv8jQdMH0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "DyXPuTl3MPfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Hx9ZCxeJMeW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train,y_train,batch_size=32,epochs = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux5eF9sVMjND",
        "outputId": "ac3e45c0-a4f7-49d7-8609-fdfc63294097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7289\n",
            "Epoch 2/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7289\n",
            "Epoch 3/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7289\n",
            "Epoch 4/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7303\n",
            "Epoch 5/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5507 - accuracy: 0.7303\n",
            "Epoch 6/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7317\n",
            "Epoch 7/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7303\n",
            "Epoch 8/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7303\n",
            "Epoch 9/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7275\n",
            "Epoch 10/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7317\n",
            "Epoch 11/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7317\n",
            "Epoch 12/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7317\n",
            "Epoch 13/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7317\n",
            "Epoch 14/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7303\n",
            "Epoch 15/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7289\n",
            "Epoch 16/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7289\n",
            "Epoch 17/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7289\n",
            "Epoch 18/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7303\n",
            "Epoch 19/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7289\n",
            "Epoch 20/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7247\n",
            "Epoch 21/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7289\n",
            "Epoch 22/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7317\n",
            "Epoch 23/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7331\n",
            "Epoch 24/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7289\n",
            "Epoch 25/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7331\n",
            "Epoch 26/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7331\n",
            "Epoch 27/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7303\n",
            "Epoch 28/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7289\n",
            "Epoch 29/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7303\n",
            "Epoch 30/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7275\n",
            "Epoch 31/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7317\n",
            "Epoch 32/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7261\n",
            "Epoch 33/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7303\n",
            "Epoch 34/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7303\n",
            "Epoch 35/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7360\n",
            "Epoch 36/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7346\n",
            "Epoch 37/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7360\n",
            "Epoch 38/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7346\n",
            "Epoch 39/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7360\n",
            "Epoch 40/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7317\n",
            "Epoch 41/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7374\n",
            "Epoch 42/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7346\n",
            "Epoch 43/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7360\n",
            "Epoch 44/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7275\n",
            "Epoch 45/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7303\n",
            "Epoch 46/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7317\n",
            "Epoch 47/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7360\n",
            "Epoch 48/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7331\n",
            "Epoch 49/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7317\n",
            "Epoch 50/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7346\n",
            "Epoch 51/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7346\n",
            "Epoch 52/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7346\n",
            "Epoch 53/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7289\n",
            "Epoch 54/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7346\n",
            "Epoch 55/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7303\n",
            "Epoch 56/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7303\n",
            "Epoch 57/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7360\n",
            "Epoch 58/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7303\n",
            "Epoch 59/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7275\n",
            "Epoch 60/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7303\n",
            "Epoch 61/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7331\n",
            "Epoch 62/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7360\n",
            "Epoch 63/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7360\n",
            "Epoch 64/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7388\n",
            "Epoch 65/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7317\n",
            "Epoch 66/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7331\n",
            "Epoch 67/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7346\n",
            "Epoch 68/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7360\n",
            "Epoch 69/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7331\n",
            "Epoch 70/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7317\n",
            "Epoch 71/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7430\n",
            "Epoch 72/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7360\n",
            "Epoch 73/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7346\n",
            "Epoch 74/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7331\n",
            "Epoch 75/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7346\n",
            "Epoch 76/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7317\n",
            "Epoch 77/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7331\n",
            "Epoch 78/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7360\n",
            "Epoch 79/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7430\n",
            "Epoch 80/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7331\n",
            "Epoch 81/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7346\n",
            "Epoch 82/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7374\n",
            "Epoch 83/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7303\n",
            "Epoch 84/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7346\n",
            "Epoch 85/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7331\n",
            "Epoch 86/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7303\n",
            "Epoch 87/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7346\n",
            "Epoch 88/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7346\n",
            "Epoch 89/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7289\n",
            "Epoch 90/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7331\n",
            "Epoch 91/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7388\n",
            "Epoch 92/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7346\n",
            "Epoch 93/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7289\n",
            "Epoch 94/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7346\n",
            "Epoch 95/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7388\n",
            "Epoch 96/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7346\n",
            "Epoch 97/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7317\n",
            "Epoch 98/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7346\n",
            "Epoch 99/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7346\n",
            "Epoch 100/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7388\n",
            "Epoch 101/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7360\n",
            "Epoch 102/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7303\n",
            "Epoch 103/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7360\n",
            "Epoch 104/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7360\n",
            "Epoch 105/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7317\n",
            "Epoch 106/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7346\n",
            "Epoch 107/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7416\n",
            "Epoch 108/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7402\n",
            "Epoch 109/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7317\n",
            "Epoch 110/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7346\n",
            "Epoch 111/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7430\n",
            "Epoch 112/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7388\n",
            "Epoch 113/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7331\n",
            "Epoch 114/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7360\n",
            "Epoch 115/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7388\n",
            "Epoch 116/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7346\n",
            "Epoch 117/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7317\n",
            "Epoch 118/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7331\n",
            "Epoch 119/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7331\n",
            "Epoch 120/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7360\n",
            "Epoch 121/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7374\n",
            "Epoch 122/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7374\n",
            "Epoch 123/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7331\n",
            "Epoch 124/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7360\n",
            "Epoch 125/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7416\n",
            "Epoch 126/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7331\n",
            "Epoch 127/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5462 - accuracy: 0.7388\n",
            "Epoch 128/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7402\n",
            "Epoch 129/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7388\n",
            "Epoch 130/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.7402\n",
            "Epoch 131/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7402\n",
            "Epoch 132/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5446 - accuracy: 0.7374\n",
            "Epoch 133/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7416\n",
            "Epoch 134/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7374\n",
            "Epoch 135/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7374\n",
            "Epoch 136/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7402\n",
            "Epoch 137/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5449 - accuracy: 0.7402\n",
            "Epoch 138/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7388\n",
            "Epoch 139/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7402\n",
            "Epoch 140/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7402\n",
            "Epoch 141/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7388\n",
            "Epoch 142/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7388\n",
            "Epoch 143/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7402\n",
            "Epoch 144/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5443 - accuracy: 0.7402\n",
            "Epoch 145/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5440 - accuracy: 0.7416\n",
            "Epoch 146/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7388\n",
            "Epoch 147/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5436 - accuracy: 0.7374\n",
            "Epoch 148/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5439 - accuracy: 0.7388\n",
            "Epoch 149/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7430\n",
            "Epoch 150/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7388\n",
            "Epoch 151/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5441 - accuracy: 0.7374\n",
            "Epoch 152/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7360\n",
            "Epoch 153/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7402\n",
            "Epoch 154/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7374\n",
            "Epoch 155/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7388\n",
            "Epoch 156/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7388\n",
            "Epoch 157/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5435 - accuracy: 0.7388\n",
            "Epoch 158/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7388\n",
            "Epoch 159/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7374\n",
            "Epoch 160/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5442 - accuracy: 0.7430\n",
            "Epoch 161/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7360\n",
            "Epoch 162/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5433 - accuracy: 0.7416\n",
            "Epoch 163/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7416\n",
            "Epoch 164/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5433 - accuracy: 0.7416\n",
            "Epoch 165/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7402\n",
            "Epoch 166/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7374\n",
            "Epoch 167/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5429 - accuracy: 0.7388\n",
            "Epoch 168/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7388\n",
            "Epoch 169/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7388\n",
            "Epoch 170/200\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.5432 - accuracy: 0.7360\n",
            "Epoch 171/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7374\n",
            "Epoch 172/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5426 - accuracy: 0.7402\n",
            "Epoch 173/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7388\n",
            "Epoch 174/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7388\n",
            "Epoch 175/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7416\n",
            "Epoch 176/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.7402\n",
            "Epoch 177/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7430\n",
            "Epoch 178/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7402\n",
            "Epoch 179/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5427 - accuracy: 0.7402\n",
            "Epoch 180/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7388\n",
            "Epoch 181/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7402\n",
            "Epoch 182/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7416\n",
            "Epoch 183/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7416\n",
            "Epoch 184/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7388\n",
            "Epoch 185/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7402\n",
            "Epoch 186/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7388\n",
            "Epoch 187/200\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7402\n",
            "Epoch 188/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7388\n",
            "Epoch 189/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7416\n",
            "Epoch 190/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7416\n",
            "Epoch 191/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7416\n",
            "Epoch 192/200\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.5428 - accuracy: 0.7402\n",
            "Epoch 193/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7388\n",
            "Epoch 194/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7402\n",
            "Epoch 195/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7388\n",
            "Epoch 196/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7430\n",
            "Epoch 197/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7388\n",
            "Epoch 198/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7416\n",
            "Epoch 199/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7416\n",
            "Epoch 200/200\n",
            "23/23 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7388\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8f0b0c9590>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=ann.predict(X_test)\n",
        "y_pred=(y_pred>0.5)\n",
        "#y_pred=y_pred.astype(int)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5ORRhVMMvzF",
        "outputId": "acbf9730-9c83-4b18-d3a0-28d33a21b642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=ann.predict(X_test)\n",
        "#y_pred=(y_pred>0.5)\n",
        "#y_pred=y_pred.astype(int)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcmN6AoHM17v",
        "outputId": "276d4988-0096-4d81-994c-415f982368c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9324329 ],\n",
              "       [0.8768449 ],\n",
              "       [0.2031182 ],\n",
              "       [0.7007582 ],\n",
              "       [0.70658684],\n",
              "       [0.20229161],\n",
              "       [0.8885407 ],\n",
              "       [0.2031182 ],\n",
              "       [0.20229161],\n",
              "       [0.20236042],\n",
              "       [0.46103287],\n",
              "       [0.41193557],\n",
              "       [0.25269234],\n",
              "       [0.20575243],\n",
              "       [0.843573  ],\n",
              "       [0.31779227],\n",
              "       [0.20241764],\n",
              "       [0.20481369],\n",
              "       [0.20277354],\n",
              "       [0.316106  ],\n",
              "       [0.31133306],\n",
              "       [0.20241764],\n",
              "       [0.34764677],\n",
              "       [0.06270161],\n",
              "       [0.67841285],\n",
              "       [0.2000381 ],\n",
              "       [0.88771975],\n",
              "       [0.20045778],\n",
              "       [0.23014218],\n",
              "       [0.20269305],\n",
              "       [0.86753017],\n",
              "       [0.52458686],\n",
              "       [0.19930533],\n",
              "       [0.01401865],\n",
              "       [0.20269305],\n",
              "       [0.2000381 ],\n",
              "       [0.31519997],\n",
              "       [0.8768449 ],\n",
              "       [0.207149  ],\n",
              "       [0.28152162],\n",
              "       [0.35316682],\n",
              "       [0.31747222],\n",
              "       [0.20229161],\n",
              "       [0.15576077],\n",
              "       [0.31133306],\n",
              "       [0.30485082],\n",
              "       [0.8039942 ],\n",
              "       [0.20269305],\n",
              "       [0.91515195],\n",
              "       [0.20739406],\n",
              "       [0.85315514],\n",
              "       [0.4139144 ],\n",
              "       [0.20263577],\n",
              "       [0.7538856 ],\n",
              "       [0.7232475 ],\n",
              "       [0.82001543],\n",
              "       [0.20250958],\n",
              "       [0.2005628 ],\n",
              "       [0.48741645],\n",
              "       [0.31133306],\n",
              "       [0.70343465],\n",
              "       [0.06270161],\n",
              "       [0.7007582 ],\n",
              "       [0.2031182 ],\n",
              "       [0.20269305],\n",
              "       [0.20269305],\n",
              "       [0.8524266 ],\n",
              "       [0.8930842 ],\n",
              "       [0.4317212 ],\n",
              "       [0.41395038],\n",
              "       [0.25503224],\n",
              "       [0.20269305],\n",
              "       [0.31133306],\n",
              "       [0.2851728 ],\n",
              "       [0.26276296],\n",
              "       [0.332688  ],\n",
              "       [0.20250958],\n",
              "       [0.20159316],\n",
              "       [0.4946329 ],\n",
              "       [0.34764677],\n",
              "       [0.20398197],\n",
              "       [0.5047398 ],\n",
              "       [0.41304073],\n",
              "       [0.20174196],\n",
              "       [0.28150463],\n",
              "       [0.2031182 ],\n",
              "       [0.8168044 ],\n",
              "       [0.2031182 ],\n",
              "       [0.20224565],\n",
              "       [0.7092893 ],\n",
              "       [0.01401865],\n",
              "       [0.23333639],\n",
              "       [0.44501245],\n",
              "       [0.91515195],\n",
              "       [0.31779227],\n",
              "       [0.31779227],\n",
              "       [0.2850428 ],\n",
              "       [0.69016474],\n",
              "       [0.24738652],\n",
              "       [0.203809  ],\n",
              "       [0.34764677],\n",
              "       [0.31779227],\n",
              "       [0.35316682],\n",
              "       [0.19972384],\n",
              "       [0.2031182 ],\n",
              "       [0.6005609 ],\n",
              "       [0.4131513 ],\n",
              "       [0.2005628 ],\n",
              "       [0.31133306],\n",
              "       [0.69723064],\n",
              "       [0.34764677],\n",
              "       [0.6827507 ],\n",
              "       [0.35919398],\n",
              "       [0.21543631],\n",
              "       [0.08479211],\n",
              "       [0.2031182 ],\n",
              "       [0.28169405],\n",
              "       [0.22992134],\n",
              "       [0.84204924],\n",
              "       [0.66939807],\n",
              "       [0.20229161],\n",
              "       [0.66939807],\n",
              "       [0.7121974 ],\n",
              "       [0.4129302 ],\n",
              "       [0.06270161],\n",
              "       [0.45869392],\n",
              "       [0.37633303],\n",
              "       [0.4139725 ],\n",
              "       [0.2031182 ],\n",
              "       [0.2031182 ],\n",
              "       [0.4542689 ],\n",
              "       [0.20809561],\n",
              "       [0.31779227],\n",
              "       [0.38595778],\n",
              "       [0.41193557],\n",
              "       [0.2031182 ],\n",
              "       [0.32521105],\n",
              "       [0.49003735],\n",
              "       [0.20229161],\n",
              "       [0.20257846],\n",
              "       [0.706207  ],\n",
              "       [0.3139081 ],\n",
              "       [0.20277354],\n",
              "       [0.41299745],\n",
              "       [0.20269305],\n",
              "       [0.41204602],\n",
              "       [0.31779227],\n",
              "       [0.20045778],\n",
              "       [0.20241764],\n",
              "       [0.31747222],\n",
              "       [0.44517866],\n",
              "       [0.35265777],\n",
              "       [0.25472465],\n",
              "       [0.61974394],\n",
              "       [0.35316682],\n",
              "       [0.31747222],\n",
              "       [0.7538856 ],\n",
              "       [0.20229161],\n",
              "       [0.20229161],\n",
              "       [0.2850428 ],\n",
              "       [0.31779227],\n",
              "       [0.7564559 ],\n",
              "       [0.4139144 ],\n",
              "       [0.2005628 ],\n",
              "       [0.7722125 ],\n",
              "       [0.87978137],\n",
              "       [0.8930842 ],\n",
              "       [0.44517866],\n",
              "       [0.2026473 ],\n",
              "       [0.35316682],\n",
              "       [0.35316682],\n",
              "       [0.70658684],\n",
              "       [0.31779227],\n",
              "       [0.3190927 ],\n",
              "       [0.20229161],\n",
              "       [0.20236042],\n",
              "       [0.20229161],\n",
              "       [0.7990718 ],\n",
              "       [0.26137906]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** implementing Support Vector Machine (SVM)**"
      ],
      "metadata": {
        "id": "WKMOnXRvPrjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh-hcJ9pPt5s",
        "outputId": "dfb1fe32-157a-47b3-e3f5-4f710777151f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = clf.predict(X_test)\n",
        "yhat [0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWPj_eLZQWGp",
        "outputId": "08142bde-a782-48d7-d52a-b57760d65f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MFeDnSEQiS0",
        "outputId": "cafbf6a1-2459-480e-f63b-3128f9363af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set Accuracy:  0.6815642458100558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modellling - Logistic Regression**"
      ],
      "metadata": {
        "id": "Wm2zZs9HRJaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = LogisticRegression().fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "YSO963uiRYF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = LR.predict(X_test)\n",
        "yhat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pysHbUMRchY",
        "outputId": "20888088-1e60-40b1-d916-78ecf54a90bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat_prob = LR.predict_proba(X_test)\n",
        "yhat_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUn77d-VRhaQ",
        "outputId": "bb704cf9-ca8c-4a62-b0ed-66b8c79665b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45239648, 0.54760352],\n",
              "       [0.36863286, 0.63136714],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.4224978 , 0.5775022 ],\n",
              "       [0.53781597, 0.46218403],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.31245342, 0.68754658],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.76360493, 0.23639507],\n",
              "       [0.71910951, 0.28089049],\n",
              "       [0.41034846, 0.58965154],\n",
              "       [0.78778014, 0.21221986],\n",
              "       [0.76266256, 0.23733744],\n",
              "       [0.39945976, 0.60054024],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.76358895, 0.23641105],\n",
              "       [0.76292245, 0.23707755],\n",
              "       [0.76348968, 0.23651032],\n",
              "       [0.60933944, 0.39066056],\n",
              "       [0.61121201, 0.38878799],\n",
              "       [0.76358895, 0.23641105],\n",
              "       [0.5954265 , 0.4045735 ],\n",
              "       [0.74218443, 0.25781557],\n",
              "       [0.42540795, 0.57459205],\n",
              "       [0.76410392, 0.23589608],\n",
              "       [0.3420386 , 0.6579614 ],\n",
              "       [0.7640272 , 0.2359728 ],\n",
              "       [0.75839968, 0.24160032],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.39415447, 0.60584553],\n",
              "       [0.69384793, 0.30615207],\n",
              "       [0.76423814, 0.23576186],\n",
              "       [0.79760726, 0.20239274],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.76410392, 0.23589608],\n",
              "       [0.60969396, 0.39030604],\n",
              "       [0.36863286, 0.63136714],\n",
              "       [0.76227718, 0.23772282],\n",
              "       [0.78260617, 0.21739383],\n",
              "       [0.62790981, 0.37209019],\n",
              "       [0.44733519, 0.55266481],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.70361714, 0.29638286],\n",
              "       [0.61121201, 0.38878799],\n",
              "       [0.77859135, 0.22140865],\n",
              "       [0.55153605, 0.44846395],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.43872992, 0.56127008],\n",
              "       [0.76220969, 0.23779031],\n",
              "       [0.42047211, 0.57952789],\n",
              "       [0.41959517, 0.58040483],\n",
              "       [0.7635281 , 0.2364719 ],\n",
              "       [0.35903113, 0.64096887],\n",
              "       [0.53992657, 0.46007343],\n",
              "       [0.52441207, 0.47558793],\n",
              "       [0.76356329, 0.23643671],\n",
              "       [0.76400802, 0.23599198],\n",
              "       [0.72211907, 0.27788093],\n",
              "       [0.61121201, 0.38878799],\n",
              "       [0.22827298, 0.77172702],\n",
              "       [0.74218443, 0.25781557],\n",
              "       [0.4224978 , 0.5775022 ],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.35099459, 0.64900541],\n",
              "       [0.38754313, 0.61245687],\n",
              "       [0.7157123 , 0.2842877 ],\n",
              "       [0.4197636 , 0.5802364 ],\n",
              "       [0.78734993, 0.21265007],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.61121201, 0.38878799],\n",
              "       [0.75079506, 0.24920494],\n",
              "       [0.78594225, 0.21405775],\n",
              "       [0.80882612, 0.19117388],\n",
              "       [0.76356329, 0.23643671],\n",
              "       [0.76381936, 0.23618064],\n",
              "       [0.72293671, 0.27706329],\n",
              "       [0.72416158, 0.27583842],\n",
              "       [0.7631533 , 0.2368467 ],\n",
              "       [0.72407896, 0.27592104],\n",
              "       [0.41550685, 0.58449315],\n",
              "       [0.76377774, 0.23622226],\n",
              "       [0.78260914, 0.21739086],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.56360868, 0.43639132],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.76363697, 0.23636303],\n",
              "       [0.42135599, 0.57864401],\n",
              "       [0.79760726, 0.20239274],\n",
              "       [0.7579315 , 0.2420685 ],\n",
              "       [0.71726122, 0.28273878],\n",
              "       [0.43872992, 0.56127008],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.62177659, 0.37822341],\n",
              "       [0.36743888, 0.63256112],\n",
              "       [0.3774884 , 0.6225116 ],\n",
              "       [0.76320138, 0.23679862],\n",
              "       [0.72416158, 0.27583842],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.62790981, 0.37209019],\n",
              "       [0.76416145, 0.23583855],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.25111925, 0.74888075],\n",
              "       [0.41602373, 0.58397627],\n",
              "       [0.76400802, 0.23599198],\n",
              "       [0.61121201, 0.38878799],\n",
              "       [0.36655728, 0.63344272],\n",
              "       [0.72416158, 0.27583842],\n",
              "       [0.17464775, 0.82535225],\n",
              "       [0.64791553, 0.35208447],\n",
              "       [0.48954854, 0.51045146],\n",
              "       [0.78033403, 0.21966597],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.78257597, 0.21742403],\n",
              "       [0.7584322 , 0.2415678 ],\n",
              "       [0.39977466, 0.60022534],\n",
              "       [0.42655265, 0.57344735],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.42655265, 0.57344735],\n",
              "       [0.33332777, 0.66667223],\n",
              "       [0.41499015, 0.58500985],\n",
              "       [0.74218443, 0.25781557],\n",
              "       [0.7188408 , 0.2811592 ],\n",
              "       [0.80260595, 0.19739405],\n",
              "       [0.41986726, 0.58013274],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.54352238, 0.45647762],\n",
              "       [0.7620168 , 0.2379832 ],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.79904221, 0.20095779],\n",
              "       [0.41034846, 0.58965154],\n",
              "       [0.76339361, 0.23660639],\n",
              "       [0.77550707, 0.22449293],\n",
              "       [0.69681034, 0.30318966],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.76354409, 0.23645591],\n",
              "       [0.36542163, 0.63457837],\n",
              "       [0.61020022, 0.38979978],\n",
              "       [0.76348968, 0.23651032],\n",
              "       [0.41530449, 0.58469551],\n",
              "       [0.76351212, 0.23648788],\n",
              "       [0.41086343, 0.58913657],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.7640272 , 0.2359728 ],\n",
              "       [0.76358895, 0.23641105],\n",
              "       [0.44733519, 0.55266481],\n",
              "       [0.39600851, 0.60399149],\n",
              "       [0.62691495, 0.37308505],\n",
              "       [0.78740636, 0.21259364],\n",
              "       [0.63178678, 0.36821322],\n",
              "       [0.62790981, 0.37209019],\n",
              "       [0.44733519, 0.55266481],\n",
              "       [0.35903113, 0.64096887],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.62177659, 0.37822341],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.20977469, 0.79022531],\n",
              "       [0.41959517, 0.58040483],\n",
              "       [0.76400802, 0.23599198],\n",
              "       [0.24771106, 0.75228894],\n",
              "       [0.37108774, 0.62891226],\n",
              "       [0.38754313, 0.61245687],\n",
              "       [0.39600851, 0.60399149],\n",
              "       [0.76352488, 0.23647512],\n",
              "       [0.62790981, 0.37209019],\n",
              "       [0.62790981, 0.37209019],\n",
              "       [0.53781597, 0.46218403],\n",
              "       [0.60868075, 0.39131925],\n",
              "       [0.60817378, 0.39182622],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.76360493, 0.23639507],\n",
              "       [0.76362414, 0.23637586],\n",
              "       [0.35220463, 0.64779537],\n",
              "       [0.78619274, 0.21380726]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWyiN2MCR7Jd",
        "outputId": "bdc0692e-93cb-4f2b-86c6-3bb74125dcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set Accuracy:  0.6536312849162011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementing ANN linear regression model using TensorFlow**"
      ],
      "metadata": {
        "id": "8EZJPh6KTXlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('FuelConsumption.csv')\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cqL7xFtTlql",
        "outputId": "f860c716-21dc-4fdd-f2f8-1da59c5fbb90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      MODELYEAR   MAKE       MODEL    VEHICLECLASS  ENGINESIZE  CYLINDERS  \\\n",
            "0          2014  ACURA         ILX         COMPACT         2.0          4   \n",
            "1          2014  ACURA         ILX         COMPACT         2.4          4   \n",
            "2          2014  ACURA  ILX HYBRID         COMPACT         1.5          4   \n",
            "3          2014  ACURA     MDX 4WD     SUV - SMALL         3.5          6   \n",
            "4          2014  ACURA     RDX AWD     SUV - SMALL         3.5          6   \n",
            "...         ...    ...         ...             ...         ...        ...   \n",
            "1062       2014  VOLVO    XC60 AWD     SUV - SMALL         3.0          6   \n",
            "1063       2014  VOLVO    XC60 AWD     SUV - SMALL         3.2          6   \n",
            "1064       2014  VOLVO    XC70 AWD     SUV - SMALL         3.0          6   \n",
            "1065       2014  VOLVO    XC70 AWD     SUV - SMALL         3.2          6   \n",
            "1066       2014  VOLVO    XC90 AWD  SUV - STANDARD         3.2          6   \n",
            "\n",
            "     TRANSMISSION FUELTYPE  FUELCONSUMPTION_CITY  FUELCONSUMPTION_HWY  \\\n",
            "0             AS5        Z                   9.9                  6.7   \n",
            "1              M6        Z                  11.2                  7.7   \n",
            "2             AV7        Z                   6.0                  5.8   \n",
            "3             AS6        Z                  12.7                  9.1   \n",
            "4             AS6        Z                  12.1                  8.7   \n",
            "...           ...      ...                   ...                  ...   \n",
            "1062          AS6        X                  13.4                  9.8   \n",
            "1063          AS6        X                  13.2                  9.5   \n",
            "1064          AS6        X                  13.4                  9.8   \n",
            "1065          AS6        X                  12.9                  9.3   \n",
            "1066          AS6        X                  14.9                 10.2   \n",
            "\n",
            "      FUELCONSUMPTION_COMB  FUELCONSUMPTION_COMB_MPG  CO2EMISSIONS  \n",
            "0                      8.5                        33           196  \n",
            "1                      9.6                        29           221  \n",
            "2                      5.9                        48           136  \n",
            "3                     11.1                        25           255  \n",
            "4                     10.6                        27           244  \n",
            "...                    ...                       ...           ...  \n",
            "1062                  11.8                        24           271  \n",
            "1063                  11.5                        25           264  \n",
            "1064                  11.8                        24           271  \n",
            "1065                  11.3                        25           260  \n",
            "1066                  12.8                        22           294  \n",
            "\n",
            "[1067 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wYPB-7qT8tw",
        "outputId": "f1761a24-c559-400b-ebd1-b6e0b04e3630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1067 entries, 0 to 1066\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   MODELYEAR                 1067 non-null   int64  \n",
            " 1   MAKE                      1067 non-null   object \n",
            " 2   MODEL                     1067 non-null   object \n",
            " 3   VEHICLECLASS              1067 non-null   object \n",
            " 4   ENGINESIZE                1067 non-null   float64\n",
            " 5   CYLINDERS                 1067 non-null   int64  \n",
            " 6   TRANSMISSION              1067 non-null   object \n",
            " 7   FUELTYPE                  1067 non-null   object \n",
            " 8   FUELCONSUMPTION_CITY      1067 non-null   float64\n",
            " 9   FUELCONSUMPTION_HWY       1067 non-null   float64\n",
            " 10  FUELCONSUMPTION_COMB      1067 non-null   float64\n",
            " 11  FUELCONSUMPTION_COMB_MPG  1067 non-null   int64  \n",
            " 12  CO2EMISSIONS              1067 non-null   int64  \n",
            "dtypes: float64(4), int64(4), object(5)\n",
            "memory usage: 108.5+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.asarray(df1[['CYLINDERS']])\n",
        "X[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWmUwlz5UOfx",
        "outputId": "ecd17b6b-d213-419f-873a-a4f0bd9792a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4],\n",
              "       [4],\n",
              "       [4],\n",
              "       [6],\n",
              "       [6]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.asarray(df1['CO2EMISSIONS'])\n",
        "y [0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdMXKL9VUrP3",
        "outputId": "9249d602-d80d-4235-aaab-10ef79e9ef79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([196, 221, 136, 255, 244])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4QydtceUwox",
        "outputId": "b3f399e5-b512-4232-e1be-4d9d74ee97a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (853, 1) (853,)\n",
            "Test set: (214, 1) (214,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('X_train') \n",
        "plt.ylabel('y_train') \n",
        "plt.scatter(X_train, y_train)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "um4gqHSRVVXZ",
        "outputId": "9ddc5d8e-06a8-496b-8055-f357ee64d6dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "JhASCe0hVbw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(units=1))"
      ],
      "metadata": {
        "id": "f1EY2j3aVguq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.1)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt)"
      ],
      "metadata": {
        "id": "jpFv-OmYVlDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-xMqHZIV2kl",
        "outputId": "acd0386c-01dc-4fa1-d95e-065da0283ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 3ms/step - loss: 69001.3750\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 59648.8867\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 51281.3633\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 43835.1758\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 37273.9922\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 31542.0625\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 26556.2305\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 22234.5234\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 18519.6211\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 15354.0537\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 12696.8643\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 10451.0303\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 8598.8662\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 7054.5068\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 5810.9321\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 4802.9653\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 3982.8259\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 3342.1975\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 2832.2070\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 2440.9983\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 2135.1409\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1905.1947\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1731.3284\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1599.1411\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1504.4038\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1435.8721\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1382.7747\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1346.8846\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1319.9430\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1302.2202\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1288.0115\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1280.0093\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1272.9462\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1268.9906\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1265.9022\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1263.3760\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1261.6404\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1260.2645\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1259.3329\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1257.7642\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1257.1090\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1255.7368\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1254.9727\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1254.1121\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1253.1792\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1252.7024\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1251.8477\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1250.5250\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1249.5798\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1248.7574\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1247.7931\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1247.7257\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1246.3945\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1244.8750\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1244.4929\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1243.0100\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1242.0137\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1242.2268\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1240.0626\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1239.1392\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1238.4949\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1237.2256\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1236.1401\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1234.8945\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1233.9384\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1232.7039\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1231.7579\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1231.2251\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1229.6543\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1228.6891\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1227.5476\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1226.3818\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1225.5854\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1223.9066\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1223.0598\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1222.0441\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1221.3451\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1219.9305\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1218.5277\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1217.8307\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1215.9889\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1215.0443\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1214.2078\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1212.4139\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1211.2542\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1210.1394\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1208.9153\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1208.0801\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1206.9417\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1205.0797\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1204.2865\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1203.2203\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1201.8369\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1200.7743\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 1199.6143\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1198.4745\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1197.0215\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1196.3854\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1194.8235\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1193.6006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "print('Prediction: {}'.format(model.predict([3.5])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKp1e6FDWGYC",
        "outputId": "ea519dae-0f32-47b4-d47a-3f1038031810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [[155.56686]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get weight and bias\n",
        "weights = model.get_weights()\n",
        "weight = weights[0][0]\n",
        "bias = weights[1]\n",
        "print('weight: {} bias: {}'.format(weight, bias))\n",
        "y_learned = X_train * weight + bias \n",
        "plt.scatter(X_train, y_train, label='Observation')\n",
        "plt.plot(X_train, y_learned, color='orangered', label='Regression Model')\n",
        "plt.legend() \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "6TUBfB6aWo12",
        "outputId": "c64dac0f-5354-4391-ecd7-c1317d528a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight: [35.074] bias: [50.344868]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "test_y_ = model.predict(X_test)"
      ],
      "metadata": {
        "id": "nUnJjhfDXHSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_-y_test)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_-y_test)**2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y_,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFNJpF-uW8m5",
        "outputId": "9d552ba1-c26a-4cc1-fa3a-d9f4abfc5388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error: 68.59\n",
            "Residual sum of squares (MSE): 7544.14\n",
            "R2-score: 0.65\n"
          ]
        }
      ]
    }
  ]
}